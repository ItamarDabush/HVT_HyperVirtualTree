warning: LF will be replaced by CRLF in .idea/workspace.xml.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in models/wide_resnet_hyper_decisionet_2_split.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in trainers/baseline_trainers.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in trainers/decisionet_trainers.py.
The file will have its original line endings in your working directory
warning: LF will be replaced by CRLF in utils/metrics_tracker.py.
The file will have its original line endings in your working directory
[1mdiff --git a/.idea/workspace.xml b/.idea/workspace.xml[m
[1mindex 4bcc171..ba5dc7e 100644[m
[1m--- a/.idea/workspace.xml[m
[1m+++ b/.idea/workspace.xml[m
[36m@@ -5,20 +5,12 @@[m
   </component>[m
   <component name="ChangeListManager">[m
     <list default="true" id="6dadbdc2-e2f8-40c0-80de-3454eee95714" name="Changes" comment="">[m
[31m-      <change afterPath="$PROJECT_DIR$/models/wide_resnet_hyper_decisionet.py" afterDir="false" />[m
[31m-      <change afterPath="$PROJECT_DIR$/models/wide_resnet_hyper_decisionet_2_split.py" afterDir="false" />[m
[31m-      <change afterPath="$PROJECT_DIR$/scripts/prepare_results_to_local.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/.gitignore" beforeDir="false" afterPath="$PROJECT_DIR$/.gitignore" afterDir="false" />[m
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/custom_layers/selection_layers.py" beforeDir="false" afterPath="$PROJECT_DIR$/custom_layers/selection_layers.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/models/decisionet.py" beforeDir="false" afterPath="$PROJECT_DIR$/models/decisionet.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/models/dual_rm_hyper_decisionet.py" beforeDir="false" afterPath="$PROJECT_DIR$/models/nin_hyper_decisionet.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/models/hyper_decisionet.py" beforeDir="false" afterPath="$PROJECT_DIR$/models/hyper_decisionet_v0.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/trainers/basic_trainer.py" beforeDir="false" afterPath="$PROJECT_DIR$/trainers/basic_trainer.py" afterDir="false" />[m
[32m+[m[32m      <change beforePath="$PROJECT_DIR$/models/wide_resnet_hyper_decisionet_2_split.py" beforeDir="false" afterPath="$PROJECT_DIR$/models/wide_resnet_hyper_decisionet_2_split.py" afterDir="false" />[m
[32m+[m[32m      <change beforePath="$PROJECT_DIR$/trainers/baseline_trainers.py" beforeDir="false" afterPath="$PROJECT_DIR$/trainers/baseline_trainers.py" afterDir="false" />[m
       <change beforePath="$PROJECT_DIR$/trainers/decisionet_trainers.py" beforeDir="false" afterPath="$PROJECT_DIR$/trainers/decisionet_trainers.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/trainers/dual_rm_hyper_decisionet_trainer.py" beforeDir="false" afterPath="$PROJECT_DIR$/trainers/hyper_decisionet_trainer_v0.py" afterDir="false" />[m
[31m-      <change beforePath="$PROJECT_DIR$/trainers/fixed_hyper_decisionet_trainer.py" beforeDir="false" afterPath="$PROJECT_DIR$/trainers/fixed_hyper_decisionet_trainer.py" afterDir="false" />[m
       <change beforePath="$PROJECT_DIR$/trainers/hyper_decisionet_trainer.py" beforeDir="false" afterPath="$PROJECT_DIR$/trainers/hyper_decisionet_trainer.py" afterDir="false" />[m
[32m+[m[32m      <change beforePath="$PROJECT_DIR$/utils/metrics_tracker.py" beforeDir="false" afterPath="$PROJECT_DIR$/utils/metrics_tracker.py" afterDir="false" />[m
     </list>[m
     <option name="SHOW_DIALOG" value="false" />[m
     <option name="HIGHLIGHT_CONFLICTS" value="true" />[m
[36m@@ -77,7 +69,7 @@[m
       <recent name="C:\Users\Itamar-pc\Desktop\Sofware_Thesis\HyperDecisioNet_remote\trainers" />[m
     </key>[m
   </component>[m
[31m-  <component name="RunManager" selected="Python.hyper_decisionet_validate">[m
[32m+[m[32m  <component name="RunManager" selected="Python.hyper_decisionet_trainer">[m
     <configuration default="true" type="PythonConfigurationType" factoryName="Python">[m
       <module name="HyperDecisioNet_remote" />[m
       <option name="INTERPRETER_OPTIONS" value="" />[m
[36m@@ -121,7 +113,7 @@[m
         </option>[m
       </PathMappingSettings>[m
       <option name="SCRIPT_NAME" value="$PROJECT_DIR$/trainers/baseline_trainers.py" />[m
[31m-      <option name="PARAMETERS" value="-d CIFAR10 -e nin --network_type nin -w /home/itamar/HyperDecisioNet/checkpoints/CIFAR10_nin/best_ckpt.pth" />[m
[32m+[m[32m      <option name="PARAMETERS" value="-d FashionMNIST -e nin --network_type nin" />[m
       <option name="SHOW_COMMAND_LINE" value="false" />[m
       <option name="EMULATE_TERMINAL" value="false" />[m
       <option name="MODULE_MODE" value="false" />[m
[36m@@ -162,7 +154,7 @@[m
       <option name="ADD_SOURCE_ROOTS" value="true" />[m
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />[m
       <option name="SCRIPT_NAME" value="$PROJECT_DIR$/trainers/hyper_decisionet_trainer.py" />[m
[31m-      <option name="PARAMETERS" value="-d CIFAR100 -e Hyper_decisio_wrn_1_split_1 --network_type hyper_decisio_wrn --beta 3 --augment" />[m
[32m+[m[32m      <option name="PARAMETERS" value="-d FashionMNIST -e expirements --network_type hyper_decisio_nin --beta 3" />[m
       <option name="SHOW_COMMAND_LINE" value="true" />[m
       <option name="EMULATE_TERMINAL" value="false" />[m
       <option name="MODULE_MODE" value="false" />[m
[36m@@ -181,7 +173,7 @@[m
       <option name="ADD_SOURCE_ROOTS" value="true" />[m
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />[m
       <option name="SCRIPT_NAME" value="$PROJECT_DIR$/trainers/hyper_decisionet_trainer.py" />[m
[31m-      <option name="PARAMETERS" value="-d CIFAR100 -e hyper_decisio_wrn --network_type hyper_decisio_wrn --wrn_cfg_name 100_baseline --beta 5 -w /home/itamar/HyperDecisioNet/checkpoints/CIFAR100_Hyper_decisio_wrn_new_hyper_1/best_ckpt.pth --include_top5" />[m
[32m+[m[32m      <option name="PARAMETERS" value="-d CIFAR100 -e hyper_decisio_wrn --network_type hyper_decisio_wrn --wrn_cfg_name 100_baseline --beta 5 -w /home/itamar/HyperDecisioNet/checkpoints/CIFAR100_Hyper_decisio_wrn_2_split/best_ckpt.pth --include_top5" />[m
       <option name="SHOW_COMMAND_LINE" value="true" />[m
       <option name="EMULATE_TERMINAL" value="false" />[m
       <option name="MODULE_MODE" value="false" />[m
[36m@@ -258,7 +250,7 @@[m
       <workItem from="1716186511071" duration="91147000" />[m
       <workItem from="1718257300648" duration="3304000" />[m
       <workItem from="1719409454535" duration="12629000" />[m
[31m-      <workItem from="1720081173382" duration="282321000" />[m
[32m+[m[32m      <workItem from="1720081173382" duration="304823000" />[m
     </task>[m
     <servers />[m
   </component>[m
[36m@@ -295,9 +287,9 @@[m
     </breakpoint-manager>[m
   </component>[m
   <component name="com.intellij.coverage.CoverageDataManagerImpl">[m
[31m-    <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$baseline_trainers.coverage" NAME="baseline_trainers Coverage Results" MODIFIED="1721715435270" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/trainers" />[m
[32m+[m[32m    <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$baseline_trainers.coverage" NAME="baseline_trainers Coverage Results" MODIFIED="1723016581903" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/trainers" />[m
     <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$find_preamble.coverage" NAME="find_preamble Coverage Results" MODIFIED="1705746018528" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/scripts" />[m
[31m-    <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$dual_rm_hyper_decisionet_trainer.coverage" NAME="hyper_decisionet_trainer Coverage Results" MODIFIED="1722529020946" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/trainers" />[m
[32m+[m[32m    <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$dual_rm_hyper_decisionet_trainer.coverage" NAME="hyper_decisionet_trainer Coverage Results" MODIFIED="1723378635666" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/trainers" />[m
     <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$hyper_trainers.coverage" NAME="hyper_trainers Coverage Results" MODIFIED="1712555588268" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/trainers" />[m
     <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$find_preamble_using_gpu.coverage" NAME="find_preamble_using gpu Coverage Results" MODIFIED="1705822484357" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/scripts" />[m
     <SUITE FILE_PATH="coverage/HyperDecisioNet_remote$wide_resnet_hyper_decisionet.coverage" NAME="wide_resnet_hyper_decisionet Coverage Results" MODIFIED="1722532136484" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/models" />[m
[1mdiff --git a/models/wide_resnet_hyper_decisionet_2_split.py b/models/wide_resnet_hyper_decisionet_2_split.py[m
[1mindex 5e5ceb8..92bb47d 100644[m
[1m--- a/models/wide_resnet_hyper_decisionet_2_split.py[m
[1m+++ b/models/wide_resnet_hyper_decisionet_2_split.py[m
[36m@@ -119,7 +119,7 @@[m [mclass WideResNet_HyperDecisioNet_2_split(nn.Module):[m
     def __init__(self, depth, k, dropout_p, num_classes, num_in_channels, norm_layer=None):[m
         super().__init__()[m
         n = (depth - 4) / 6[m
[31m-        stage_sizes = [16, 16 * k, 16 * k, 16 * k][m
[32m+[m[32m        stage_sizes = [16, 16 * k, 16 * k, 32 * k][m
         in_planes = 16[m
         if norm_layer is None:[m
             norm_layer = nn.BatchNorm2d[m
[1mdiff --git a/trainers/baseline_trainers.py b/trainers/baseline_trainers.py[m
[1mindex 4386877..6fbca21 100644[m
[1m--- a/trainers/baseline_trainers.py[m
[1m+++ b/trainers/baseline_trainers.py[m
[36m@@ -110,5 +110,5 @@[m [mif __name__ == '__main__':[m
     trainer = NetworkInNetworkTrainer()[m
     # trainer = BasicClassifierTrainer()[m
     # trainer = WideResNetTrainer()[m
[31m-    # trainer.train_model()[m
[31m-    trainer.evaluate()[m
[32m+[m[32m    trainer.train_model()[m
[32m+[m[32m    # trainer.evaluate()[m
[1mdiff --git a/trainers/decisionet_trainers.py b/trainers/decisionet_trainers.py[m
[1mindex bf5c0f7..1eb25a1 100644[m
[1m--- a/trainers/decisionet_trainers.py[m
[1m+++ b/trainers/decisionet_trainers.py[m
[36m@@ -259,7 +259,7 @@[m [mclass WideResNetDecisioNetTrainer(DecisioNetTrainer):[m
 [m
 [m
 if __name__ == '__main__':[m
[31m-    # trainer = NetworkInNetworkDecisioNetTrainer()[m
[31m-    trainer = WideResNetDecisioNetTrainer()[m
[32m+[m[32m    trainer = NetworkInNetworkDecisioNetTrainer()[m
[32m+[m[32m    # trainer = WideResNetDecisioNetTrainer()[m
     trainer.train_model()[m
     # trainer.evaluate()[m
[1mdiff --git a/trainers/hyper_decisionet_trainer.py b/trainers/hyper_decisionet_trainer.py[m
[1mindex f7477e7..ae78c9e 100644[m
[1m--- a/trainers/hyper_decisionet_trainer.py[m
[1m+++ b/trainers/hyper_decisionet_trainer.py[m
[36m@@ -63,6 +63,8 @@[m [mclass DecisioNetTrainer(BasicTrainer):[m
 [m
     def _single_epoch(self, epoch: int, train_test_val: str):[m
         norm_acc, norm_loss = super()._single_epoch(epoch, train_test_val)[m
[32m+[m[32m        if (train_test_val == 'test'):[m
[32m+[m[32m            print(f'Average Leaf Entrophy: {self.metrics_tracker.get_leaf_entrophy()}')[m
         if self.use_wandb:[m
             log_dict = {f"{train_test_val}_cls_loss": self.metrics_tracker.get_norm_cls_loss(),[m
                         f"{train_test_val}_sigma_loss": self.metrics_tracker.get_norm_sigma_loss(),[m
[36m@@ -341,7 +343,7 @@[m [mclass NIN_HyperDecisioNetTrainer(DecisioNetTrainer):[m
     def _init_model(self):[m
         set_random_seed(0)[m
         model = NIN_HyperDecisioNet(input_channels=INPUT_SIZE[self.dataset_name][0])[m
[31m-        # model.apply(functools.partial(weights_init_kaiming, scale=0.01))[m
[32m+[m[32m        model.apply(functools.partial(weights_init_kaiming, scale=0.01))[m
         # model.apply(self.weights_init_xavier)[m
         return model[m
 [m
[36m@@ -399,7 +401,7 @@[m [mclass WideResNetDecisioNetTrainer(DecisioNetTrainer):[m
 [m
     def init_parser(self):[m
         parser = super().init_parser()[m
[31m-        parser.add_argument('--wrn_cfg_name', type=str, default='100_baseline_single_early', help='Name of the Wide-ResNet config')[m
[32m+[m[32m        parser.add_argument('--wrn_cfg_name', type=str, default='100_baseline', help='Name of the Wide-ResNet config')[m
         return parser[m
 [m
     def _init_config_attributes(self):[m
[36m@@ -431,12 +433,12 @@[m [mclass WideResNetDecisioNetTrainer(DecisioNetTrainer):[m
         return outputs, combined_loss[m
 [m
 if __name__ == '__main__':[m
[31m-    trainer = WideResNetDecisioNetTrainer()[m
[31m-    # trainer = NIN_HyperDecisioNetTrainer()[m
[32m+[m[32m    # trainer = WideResNetDecisioNetTrainer()[m
[32m+[m[32m    trainer = NIN_HyperDecisioNetTrainer()[m
     input_tensor = torch.randn(1, 3, 32, 32).to(trainer.device)[m
     # flops = FlopCountAnalysis(trainer.model, input_tensor)[m
     # print(f'Number Of Flops: {flops.total()}')[m
     print(f'Number Of Parameters: {sum(p.numel() for p in trainer.model.parameters() if p.requires_grad)}')[m
[31m-    # trainer.train_model()[m
[31m-    results = trainer.evaluate()[m
[31m-    prepare_output_to_local(results)[m
[32m+[m[32m    trainer.train_model()[m
[32m+[m[32m    # results = trainer.evaluate()[m
[32m+[m[32m    # prepare_output_to_local(results)[m
[1mdiff --git a/utils/metrics_tracker.py b/utils/metrics_tracker.py[m
[1mindex 30f9995..ca1909c 100644[m
[1m--- a/utils/metrics_tracker.py[m
[1m+++ b/utils/metrics_tracker.py[m
[36m@@ -2,6 +2,7 @@[m [mfrom typing import List[m
 import torch[m
 import numpy as np[m
 from utils.constants import NUM_CLASSES[m
[32m+[m[32mfrom scipy.stats import entropy[m
 [m
 [m
 def topk_correct_predictions(output: torch.Tensor, target: torch.Tensor, topk=(1,)) -> List[torch.FloatTensor]:[m
[36m@@ -242,6 +243,7 @@[m [mclass SigmaLossMetricsTracker:[m
         self.total_samples = 0[m
         self.num_batches = 0[m
         self.include_top5 = include_top5[m
[32m+[m[32m        self.total_leaf_entropy = 0[m
 [m
     def update(self, cls_loss, sigma_loss, loss, cls_outputs, cls_targets, sigma_outputs, sigma_targets):[m
         self.total_samples += cls_targets.size(0)[m
[36m@@ -260,6 +262,37 @@[m [mclass SigmaLossMetricsTracker:[m
         eq_sigma[sigma_targets == 0.5] = True[m
         self.total_sigma_correct += eq_sigma.all(dim=1).sum().item()[m
 [m
[32m+[m[32m        # avg_leaf_entropy = self.calculate_branchwise_entropy(sigma_outputs, sigma_targets)[m
[32m+[m[32m        # self.total_leaf_entropy += avg_leaf_entropy[m
[32m+[m
[32m+[m[32m    def calculate_branchwise_entropy(self, sigma_outputs, sigma_targets):[m
[32m+[m[32m        entropies = [][m
[32m+[m[32m        unique_sigma_targets = torch.unique(sigma_targets, dim=0)[m
[32m+[m
[32m+[m[32m        for branch_encoding in unique_sigma_targets:[m
[32m+[m
[32m+[m[32m            branch_idx = torch.where(sigma_targets == branch_encoding)[0][m
[32m+[m[32m            true_routing_mask = torch.all(sigma_outputs[branch_idx] == branch_encoding, dim=1)[m
[32m+[m[32m            true_routing_count = torch.sum(true_routing_mask)[m
[32m+[m[32m            target_routing_count = torch.sum(branch_idx)[m
[32m+[m
[32m+[m[32m            # Avoid division by zero[m
[32m+[m[32m            if target_routing_count > 0:[m
[32m+[m[32m                true_routing_prob = true_routing_count.float() / target_routing_count.float()[m
[32m+[m[32m                branch_entropy = self.mean_entropy(true_routing_prob, base=2)[m
[32m+[m[32m                entropies.append(branch_entropy)[m
[32m+[m
[32m+[m[32m        avg_entropy = torch.mean(torch.tensor(entropies)) if entropies else torch.tensor(0.0)[m
[32m+[m[32m        return avg_entropy[m
[32m+[m
[32m+[m[32m    def mean_entropy(self, prob, base=None, epsilon=1e-10):[m
[32m+[m[32m        # Ensure probabilities are valid[m
[32m+[m[32m        prob = prob.clamp(min=epsilon, max=1 - epsilon)[m
[32m+[m[32m        entropy = -prob * torch.log(prob) - (1 - prob) * torch.log(1 - prob)[m
[32m+[m[32m        if base is not None:[m
[32m+[m[32m            entropy /= torch.log(torch.tensor(base, dtype=entropy.dtype))[m
[32m+[m[32m        return entropy[m
[32m+[m
     def get_message_to_display(self, batch_idx):[m
         total_loss_msg = f'Total Loss: {self.total_loss / (batch_idx + 1):.3f}'[m
         cls_msg = f'Cls Loss: {self.total_cls_loss / (batch_idx + 1):.3f} | ' \[m
[36m@@ -274,6 +307,9 @@[m [mclass SigmaLossMetricsTracker:[m
         msg_to_display = '; '.join([total_loss_msg, cls_msg, sigma_msg])[m
         return msg_to_display[m
 [m
[32m+[m[32m    def get_leaf_entrophy(self):[m
[32m+[m[32m        leaf_entrophy = self.total_leaf_entropy / self.num_batches[m
[32m+[m[32m        return leaf_entrophy[m
     def get_norm_loss(self):[m
         norm_loss = self.total_loss / self.num_batches[m
         return norm_loss[m
[36m@@ -313,3 +349,4 @@[m [mclass SigmaLossMetricsTracker:[m
         self.total_sigma_correct = 0[m
         self.total_samples = 0[m
         self.num_batches = num_batches[m
[32m+[m[32m        self.total_leaf_entropy = 0[m
\ No newline at end of file[m
